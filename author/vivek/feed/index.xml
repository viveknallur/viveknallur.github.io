<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Vivek Nallur &#8211; Vivek Nallur</title>
	<atom:link href="https://viveknallur.github.io/author/vivek/feed/" rel="self" type="application/rss+xml" />
	<link>https://viveknallur.github.io</link>
	<description>The site for Vivek&#039;s (mostly) academic life</description>
	<lastBuildDate>Wed, 23 Sep 2020 10:50:12 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.4.2</generator>
	<item>
		<title>Super cool physics and AI (and Ethics)</title>
		<link>https://viveknallur.github.io/super-cool-physics-and-ai-and-ethics/</link>
					<comments>https://viveknallur.github.io/super-cool-physics-and-ai-and-ethics/#respond</comments>
		
		<dc:creator><![CDATA[Vivek Nallur]]></dc:creator>
		<pubDate>Wed, 23 Sep 2020 10:49:01 +0000</pubDate>
				<category><![CDATA[Machine Ethics]]></category>
		<guid isPermaLink="false">https://viveknallur.github.io/?p=408</guid>

					<description><![CDATA[Physicists are (sometimes) some of my favourite people. They do really cool science, and ask questions about the fundamental nature of our reality. It is very gratifying to know that some of them have also started to look back at ourselves, how we use information, and what information can tell us about the nature of [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Physicists are (sometimes) some of my favourite people. They do really cool science, and ask questions about the fundamental nature of our reality. It is very gratifying to know that some of them have also started to look back at ourselves, how we use information, and what information can tell us about the nature of our social reality. Some physicists have started to take a deeper look into the algorithms that are used at the heart of physics-computing, and wondering what impacts they (the algorithms) might have on us.</p>
<p><a href="https://www.wired.com/author/sophia-chen/">Sophia Chen,</a> writing for W.I.R.E.D magazine wrote about how the field of AI is attracting <a href="https://www.wired.com/story/to-make-fairer-ai-physicists-peer-inside-its-black-box/">physicists to peer inside the algorithms</a>. She also mentions me, and some of the questions that I think are really relevant to the field.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://viveknallur.github.io/super-cool-physics-and-ai-and-ethics/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>AAAI Spring Symposium on Implementing AI Ethics (22-24 March, 2021)</title>
		<link>https://viveknallur.github.io/aaai-spring-symposium-on-implementing-ai-ethics-22-24-march-2021/</link>
					<comments>https://viveknallur.github.io/aaai-spring-symposium-on-implementing-ai-ethics-22-24-march-2021/#respond</comments>
		
		<dc:creator><![CDATA[Vivek Nallur]]></dc:creator>
		<pubDate>Tue, 25 Aug 2020 10:37:00 +0000</pubDate>
				<category><![CDATA[Machine Ethics]]></category>
		<guid isPermaLink="false">https://viveknallur.github.io/?p=406</guid>

					<description><![CDATA[Delighted to announce that the AAAI have accepted our proposal for Implementing AI Ethics, as a part of their Spring Symposium Series. We have an excellent organizing committee with a healthy mix of industry, policy, academics and technologists. Looking forward to the speakers and participants of the Symposium, in March 2021! Here&#8217;s hoping that we [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Delighted to announce that the AAAI have accepted <a href="https://www.aaai.org/Symposia/Spring/sss21symposia.php#ss06">our proposal for Implementing AI Ethics</a>, as a part of their <a href="https://www.aaai.org/Symposia/Spring/sss21.php">Spring Symposium Series</a>. We have an excellent organizing committee with a healthy mix of industry, policy, academics and technologists. Looking forward to the speakers and participants of the Symposium, in March 2021!</p>
<p>Here&#8217;s hoping that we can all meet face-to-face!!</p>
]]></content:encoded>
					
					<wfw:commentRss>https://viveknallur.github.io/aaai-spring-symposium-on-implementing-ai-ethics-22-24-march-2021/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>ELSI Panel for OpenAAL</title>
		<link>https://viveknallur.github.io/elsi-panel-for-openaal/</link>
					<comments>https://viveknallur.github.io/elsi-panel-for-openaal/#respond</comments>
		
		<dc:creator><![CDATA[Vivek Nallur]]></dc:creator>
		<pubDate>Mon, 20 Jul 2020 14:21:20 +0000</pubDate>
				<category><![CDATA[Machine Ethics]]></category>
		<guid isPermaLink="false">https://viveknallur.github.io/?p=379</guid>

					<description><![CDATA[Very pleased to be a part of the ELSI panel on the OpenAAL project being spearheaded by the Heriot-Watt University. Ambient assisted living, especially in these locked-down times, will provide us with the ability to provide care to vulnerable segments of the population. However, with the introduction of robots into our personal space, comes the [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Very pleased to be a part of the ELSI panel on the <a href="https://ralt.hw.ac.uk/openaal.html">OpenAAL project</a> being spearheaded by the Heriot-Watt University. Ambient assisted living, especially in these locked-down times, will provide us with the ability to provide care to vulnerable segments of the population. However, with the introduction of robots into our personal space, comes the challenge of addressing its impact on the patients, their families, and other care-givers. People respond differently when interacting with machines, than they do with humans. And it is our responsibility to ensure that the outcome of introducing robots takes into account the multiple stakeholders, their views, and any ethical implications of interactions.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://viveknallur.github.io/elsi-panel-for-openaal/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>The Second Workshop on Implementing Machine Ethics</title>
		<link>https://viveknallur.github.io/the-second-workshop-on-implementing-machine-ethics/</link>
					<comments>https://viveknallur.github.io/the-second-workshop-on-implementing-machine-ethics/#respond</comments>
		
		<dc:creator><![CDATA[Vivek Nallur]]></dc:creator>
		<pubDate>Wed, 01 Jul 2020 13:04:40 +0000</pubDate>
				<category><![CDATA[Machine Ethics]]></category>
		<guid isPermaLink="false">https://viveknallur.github.io/?p=373</guid>

					<description><![CDATA[The Machine Ethics Research Group recently organized the second workshop on Implementing Machine Ethics. Due to the covid-19 lockdown, it was held in an online-only mode, with participants and presenters interacting via Zoom and Sli.do. We had some really thought-provoking talks from a variety of domains (literature, law, philosophy, computer science), and questions from a [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>The Machine Ethics Research Group recently organized the <a href="https://aristotle.ucd.ie/">second workshop on Implementing Machine Ethics</a>. Due to the covid-19 lockdown, it was held in an online-only mode, with participants and presenters interacting via Zoom and Sli.do. We had some really thought-provoking talks from a variety of domains (literature, law, philosophy, computer science), and questions from a very engaged audience. All of the presented slides can be found on the <a href="https://aristotle.ucd.ie/#schedule">website.</a> The abstracts submitted by the presenters have been uploaded to Zenodo, and can be accessed (and cited) via the DOI: <a href="https://doi.org/10.5281/zenodo.3938851"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.3938851.svg" alt="DOI" /></a></p>
<p>We are hoping to make it a continuing event and have applied to AAAI for acceptance as a regular symposium. There is a mailing list for those interested in continuing discussions or notices of collaboration opportunities. Please click <a href="https://listserv.heanet.ie/cgi-bin/wa?A0=MACHINE-ETHICS&amp;X=OP1893714A7B4A48A071" target="_blank" rel="noopener noreferrer">here</a> to sign up. The mailing list is hosted by HEANet, Ireland. You can see a &#8220;Subscribe or Unsubscribe&#8221; link in the menu on the right hand side, in a box called &#8220;Options&#8221;. Please do consider joining.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://viveknallur.github.io/the-second-workshop-on-implementing-machine-ethics/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>IEEE P7008 Standard &#8211; Ethically Driven Nudging for Robotic, Intelligent and Autonomous Systems</title>
		<link>https://viveknallur.github.io/ieee-p7008-standard-ethically-driven-nudging-for-robotic-intelligent-and-autonomous-systems/</link>
					<comments>https://viveknallur.github.io/ieee-p7008-standard-ethically-driven-nudging-for-robotic-intelligent-and-autonomous-systems/#respond</comments>
		
		<dc:creator><![CDATA[Vivek Nallur]]></dc:creator>
		<pubDate>Tue, 12 May 2020 10:56:35 +0000</pubDate>
				<category><![CDATA[Machine Ethics]]></category>
		<guid isPermaLink="false">https://viveknallur.github.io/?p=350</guid>

					<description><![CDATA[I have recently started contributing to theÂ IEEE P7008 Standards committee for Ethically Driven Nudging for Robotic, Intelligent and Autonomous Systems. A nudge is an overt or covert suggestion or manipulation designed to influence the emotions or behaviour of a user.Â  Depending on your perspective, this might seem ominous or useful. All human beings are susceptible [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>I have recently started contributing to theÂ IEEE P7008 Standards committee for Ethically Driven Nudging for Robotic, Intelligent and Autonomous Systems.</p>
<p>A nudge is an overt or covert suggestion or manipulation designed to influence the emotions or behaviour of a user.Â  Depending on your perspective, this might seem ominous or useful. All human beings are susceptible to behavioural nudges, i.e., manipulation of content, colours, choices, even the order of choices, etc., which encourage / discourage us from a particular behaviour.Â  Starting from behavioural economics, where Tversky and Kahneman showed that human beings (quite consistently) behave in irrational ways<span id="mMhX~bjiiJHWmUxDzqn0h" class="abt-citation noselect mceNonEditable" data-reflist="[&quot;165803140&quot;]" data-footnote="undefined"><sup>1</sup></span>, there has been considerable research in trying to explain how individuals evaluate choices. This is in contrast to standard economic theory that used to assume that individuals were completely rational, and always self-interested agents. Perhaps the most popular explanation of such behaviour is <a href="https://en.wikipedia.org/wiki/Predictably_Irrational">Dan Ariely&#8217;s book &#8211; Predictably Irrational</a>. Governments, organizations and companies have been trying to use these insights to influence how populations, societies and consumers behave. This has given rise to the study of theÂ <em>nudge &#8211;Â </em>subtly and adaptively influencing someone&#8217;s choice without limiting their actual choices.</p>
<p>Combined with Big Data and Machine Learning, the use of nudges can be used by systems to influence user behaviour. A common example is the use ofÂ <em>pre-checked boxes</em>. If the text next to a checkbox is boring/not clearly understood/legalese, a user is tempted to leave it as they found it. That is, if a checkbox is asking for consent to bombard you with marketing material, you are tempted to leave the checkbox checked if you don&#8217;t really understand what is being asked, or the language used is such that it insinuates a loss if you uncheck it. This is a nudge because you are quite capable of un-checking the box, but you have chosen to not do it.Â  Given the power of Big Data, an algorithm could identify which kind of nudges work on you personally, and then ensure that only those nudges are shown to you.Â  These sort of nudges can clearly be used for all kinds of purposes. For example, ensuring that users make good choices (say, encouraging them to save for retirement) or making choices where the organization benefits (say, accepting tracking cookies).</p>
<p>The IEEE committee&#8217;s focus is on how human beings (or design teams and organizations) should ensure that their nudges are ethical. There is clearly no standard system of ethics that everyone subscribes to. So the committee is focussed on specifying a design process which will at least ensure that every company/organization that creates intelligent systems that uses nudges, will explicitly confront the ethical choices it is making.</p>
<div id="abt-bibliography" class="abt-bibliography noselect mceNonEditable" data-reflist="[&quot;165803140&quot;]">
<div id="abt-bibliography__container" class="abt-bibliography__container">
<div id="165803140">
<div class="csl-entry flush">
<div class="csl-left-margin">1.</div>
<div class="csl-right-inline">Tversky A, Kahneman D. Rational Choice and the Framing of Decisions. In: <i>Multiple Criteria Decision Making and Risk Analysis Using Microcomputers</i>. Springer Berlin Heidelberg; 1989:81-126. doi:<a href="https://doi.org/10.1007/978-3-642-74919-3_4" target="_blank" rel="noopener noreferrer">10.1007/978-3-642-74919-3_4</a></div>
</div>
</div>
</div>
</div>
]]></content:encoded>
					
					<wfw:commentRss>https://viveknallur.github.io/ieee-p7008-standard-ethically-driven-nudging-for-robotic-intelligent-and-autonomous-systems/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>New PhD student starting work on Machine Ethics</title>
		<link>https://viveknallur.github.io/new-phd-student-starting-work-on-machine-ethics/</link>
					<comments>https://viveknallur.github.io/new-phd-student-starting-work-on-machine-ethics/#respond</comments>
		
		<dc:creator><![CDATA[Vivek Nallur]]></dc:creator>
		<pubDate>Wed, 22 Jan 2020 10:38:05 +0000</pubDate>
				<category><![CDATA[Machine Ethics]]></category>
		<guid isPermaLink="false">http://desktop-0gddg8k/wordpress/?p=344</guid>

					<description><![CDATA[Very excited to welcome Rajitha Ramanayake as a PhD student to work on Machine Ethics. He plans to work on techniques to reliably insert a notion of ethics into autonomous agents. Here&#8217;s hoping that it&#8217;s a great research journey, and that he enjoys the ride. His abstract, from his phd application, is as follows: Artificial [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Very excited to welcome <a href="https://www.linkedin.com/in/rajitharamanayake/">Rajitha Ramanayake</a> as a PhD student to work on Machine Ethics. He plans to work on techniques to reliably insert a notion of ethics into autonomous agents. Here&#8217;s hoping that it&#8217;s a great research journey, and that he enjoys the ride.</p>
<p>His abstract, from his phd application, is as follows:</p>
<blockquote><p>Artificial Intelligence (AI) techniques such as reinforcement learning and deepÂ learning have enjoyed some success in accomplishing tasks at human-levelÂ capability in the recent past. It is expected that several human jobs will beÂ replaced by intelligent and autonomous systems in the near future.Â When domains that have direct links/involvement with the community, such asÂ health-care, social data mining and advertising, personal assistants andÂ autonomous vehicles, use artificial intelligence, the importance of values andÂ the morality of an AI system comes into the picture. These systems couldÂ easily encounter situations that contain a moral dilemma which will affect aÂ community or an individualâ€™s life. Therefore, in order to decide which actionsÂ must be taken in such situations, we need to introduce a sense of values intoÂ these AI agents. One way to infer a sense of values onto intelligent systems isÂ by embedding ethics into them.Â As a result, there are many attempts being made to provide AI systems with aÂ sense of ethics. However, there is no general consensus on what type ofÂ ethics (i.e. utilitarian ethics, deontological ethics, virtue ethics, the principle of<br />
double effect) can/should be embedded into an AI or what Approach (i.e.Â  Evolutionary computing, Multi-agent systems, Machine learning, DeepÂ learning, Reinforcement Learning)Â  would be most suitable for implementingÂ these types of ethics. The need to find philosophical theories andÂ technological methods that can be used to build an artificial agent &#8211; and whichÂ can be entrusted to act as an ethical agent &#8211; is of vital importance in the futureÂ of intelligent agents. My research will concern itself with techniques inÂ computer science that can be used to implement ethical behaviour</p></blockquote>
<p style="text-align: left;">Let&#8217;s come back to this in four years time to see where he&#8217;s got <img src="https://s.w.org/images/core/emoji/12.0.0-1/72x72/1f609.png" alt="ðŸ˜‰" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
]]></content:encoded>
					
					<wfw:commentRss>https://viveknallur.github.io/new-phd-student-starting-work-on-machine-ethics/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Invited Talk at CERN, Geneva</title>
		<link>https://viveknallur.github.io/invited-talk-at-cern-geneva/</link>
					<comments>https://viveknallur.github.io/invited-talk-at-cern-geneva/#respond</comments>
		
		<dc:creator><![CDATA[Vivek Nallur]]></dc:creator>
		<pubDate>Thu, 22 Aug 2019 15:06:23 +0000</pubDate>
				<category><![CDATA[Machine Ethics]]></category>
		<guid isPermaLink="false">http://desktop-0gddg8k/wordpress/?p=341</guid>

					<description><![CDATA[I was recently invited by Dr. Alberto Di Meglio, head of OpenLab @ CERN to give a talk on Machine Ethics. Super-excited to interact with computer scientists, physicists and folks from multiple disciplines, and gather their views on how AI impacts society and what computer science should be doing about it. Refreshing to know that [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>I was recently invited by <a href="https://openlab.cern/team/alberto-di-meglio">Dr. Alberto Di Meglio</a>, head of OpenLab @ CERN to give a <a href="https://indico.cern.ch/event/837519/">talk on Machine Ethics</a>. Super-excited to interact with computer scientists, physicists and folks from multiple disciplines, and gather their views on how AI impacts society and what computer science should be doing about it. Refreshing to know that even high-energy physicists &#8216;get it&#8217; with regard to our (scientists&#8217;) obligations to engage deeply with society. The video of the talk can be found <a href="http://cds.cern.ch/record/2687725?ln=en">here</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://viveknallur.github.io/invited-talk-at-cern-geneva/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>New mailing list on machine ethics created</title>
		<link>https://viveknallur.github.io/new-mailing-list-on-machine-ethics-created/</link>
					<comments>https://viveknallur.github.io/new-mailing-list-on-machine-ethics-created/#respond</comments>
		
		<dc:creator><![CDATA[Vivek Nallur]]></dc:creator>
		<pubDate>Sun, 14 Jul 2019 14:54:29 +0000</pubDate>
				<category><![CDATA[Machine Ethics]]></category>
		<guid isPermaLink="false">http://desktop-0gddg8k/wordpress/?p=337</guid>

					<description><![CDATA[After the end of the first inter-disciplinary workshop on Implementing Machine Ethics, the participants agreed that it was rare for events to be truly inter-disciplinary, and that they enjoyed talking through and thinking about the multiple perspectives, about ethics inside machines. To facilitate more discussion on the topic, a mailing list was set up on [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>After the end of the <a href="https://aristotle.ucd.ie/">first inter-disciplinary workshop on Implementing Machine Ethics</a>, the participants agreed that it was rare for events to be truly inter-disciplinary, and that they enjoyed talking through and thinking about the multiple perspectives, about ethics inside machines.</p>
<p>To facilitate more discussion on the topic, a <a href="https://listserv.heanet.ie/cgi-bin/wa?A0=MACHINE-ETHICS&amp;X=OP1893714A7B4A48A071">mailing list</a> was set up on HEANet&#8217;s listserv service.Â It is meant for everyone who is interested in the inter-disciplinary aspects ofÂ <i>how</i>,Â <i>why</i>, andÂ <i>what</i>Â ethics should be implemented in machines. Clicking on the link above will take you to the HEANET website. You can see a subscribe and unsubscribe button in the menu on the right hand side called options. Please do consider joining if you are interested in society, AI, philosophy, technology, law and how they intersect.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://viveknallur.github.io/new-mailing-list-on-machine-ethics-created/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Going to AAMAS&#8217;18</title>
		<link>https://viveknallur.github.io/going-to-aamas18/</link>
					<comments>https://viveknallur.github.io/going-to-aamas18/#respond</comments>
		
		<dc:creator><![CDATA[Vivek Nallur]]></dc:creator>
		<pubDate>Fri, 06 Jul 2018 09:04:42 +0000</pubDate>
				<category><![CDATA[Vivek's Research Blog]]></category>
		<guid isPermaLink="false">https://viveknallur.github.io/?p=284</guid>

					<description><![CDATA[Excited to be going to AAMAS 2018. Presenting two papers there: JAAMAS Track &#8211; Clonal Plasticity Adapative and Learning Agents Workshop &#8211; ARENA: Towards a Game Playing Framework Looking forward to meeting the community again, and forging some new links.]]></description>
										<content:encoded><![CDATA[<p>Excited to be going to AAMAS 2018. Presenting two papers there:</p>
<ul>
<li>JAAMAS Track &#8211; <a href="https://viveknallur.github.io/research/publications/">Clonal Plasticity</a></li>
<li>Adapative and Learning Agents Workshop &#8211; <a href="https://viveknallur.github.io/research/publications/">ARENA: Towards a Game Playing Framework</a></li>
</ul>
<p>Looking forward to meeting the community again, and forging some new links.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://viveknallur.github.io/going-to-aamas18/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Implementing Ethics in Machines</title>
		<link>https://viveknallur.github.io/implementing-ethics-in-machines/</link>
					<comments>https://viveknallur.github.io/implementing-ethics-in-machines/#respond</comments>
		
		<dc:creator><![CDATA[Vivek Nallur]]></dc:creator>
		<pubDate>Thu, 28 Jun 2018 16:49:14 +0000</pubDate>
				<category><![CDATA[Machine Ethics]]></category>
		<guid isPermaLink="false">https://viveknallur.github.io/?p=270</guid>

					<description><![CDATA[If we wanted to implement ethics in a robot, how would we do it? What ethics should we implement? Are Asimov&#8217;s three laws enough? Although, there seems to be philosophical consensus that Asimov&#8217;s Three Laws of Robotics are nowhere near enough for a satisfactory ethical robot, there are still attempts at creating robots that do [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>If we wanted to implement ethics in a robot, how would we do it? What ethics should we implement? Are Asimov&#8217;s three laws enough?</p>
<p>Although, there seems to be philosophical consensus that Asimov&#8217;s Three Laws of Robotics are nowhere near enough for a satisfactory ethical robot, there are still attempts at creating robots that do implement some version of Asimov&#8217;s Laws. Perhaps this tells us something about ourselves, as human beings. Even for researchers, fiction exerts aÂ power of imagination and framingÂ that is difficult to shake off.</p>
<p><span id="more-270"></span> How do we convince others (or even ourselves) that we&#8217;ve created an ethical machine? Is it better to create machines that have some understanding of the philosophical principle, and can therefore <em>reason</em> about why it should or should not perform an action? Or should we insist on machines that willÂ <em>never</em> misbehave? The answers to these questions driveÂ <span style="text-decoration: underline;">how</span> we implement ethics. Regardless of the actual ethical principle involved, our preference for reasoning vis-a-vis safety will influence how ethics are actually embedded in the machine.</p>
<h4>LogicÂ  and Model Checking</h4>
<p>An interesting approach to implementing ethical principles into robots is the HERA approach<span id="42aQ7zKGizuj8xPCmOSFd" class="abt-citation noselect mceNonEditable" data-reflist="[&quot;1352741480&quot;]" data-footnote="undefined"><sup>1</sup></span>. HERA stands forÂ <em>Hybrid Ethical Reasoning Agents</em> and assumes that there is no right ethical theory to implement. Rather, they implement multiple moral theories, which are modelled using logical formulae. The formulae are then evaluated for their `truth&#8217;, given the consequences that arise from actions that the robot could potentially take. If a particular formula resolves to true for a certain action, then the robot is able to conclude that that action is allowed by the ethical principle implemented by that formula. This is interesting because, rather than being tied to a single ethical stance, the robot is able to evaluate the same action from multiple ethical principles and allow humans to (potentially) pick which principle to prioritize. Actions and consequences are modelled using directed acyclic graphs in a causal agency model, which are then checked using a model checker.</p>
<h4>Cognition</h4>
<p>Instead of using logic or symbolic reasoning, Vanderelst and Winfield propose a cognition based approach to implementing ethics<span id="tcFeReGZpoGzPtHuU087m" class="abt-citation noselect mceNonEditable" data-reflist="[&quot;1009922757&quot;]" data-footnote="undefined"><sup>2</sup></span>. The cognition based approach is based on some amount of evidence that considers simulation to be a key factor in &#8216;thinking&#8217;<span id="8eLDgrKkGGYNKb1xB_Smz" class="abt-citation noselect mceNonEditable" data-reflist="[&quot;1027811230&quot;]" data-footnote="undefined"><sup>3</sup></span>. That is, it appears that that functions likeÂ <em>behaviour</em>,Â <em>perception</em>, andÂ <em>anticipation</em> are made possible for human beings, due to the presence of structures in the brain that can simulate interaction with the outside world. Effectively, what simulation theory says is that thinking is the act of simulating interactions with the external environment, without actually having overt actions.Â Vanderelst and Winfield propose that this can be achieved in robots through the use of a sophisticated simulation module. Most robots follow a three-layered control architecture<span id="FFz014o5c1eZTivOollVY" class="abt-citation noselect mceNonEditable" data-reflist="[&quot;795711616&quot;]" data-footnote="undefined"><sup>4</sup></span>, with each layer acting at different time-scales and different levels of abstraction. This is enhanced with the use of one more layer called the Ethical layer. The ethical layer consists of two modules: simulation module and the evaluation module. For each possible behaviour that the robot can do, the simulation module sends a prediction of the robot and the external environment&#8217;s states to the evaluation module. The evaluation module then assigns a value to the combination of the robot&#8217;s predicted state and the world&#8217;s predicted state. Based on this value, the robot chooses to either behave in a particular manner or not.</p>
<p>&nbsp;</p>
<div id="abt-bibliography" class="abt-bibliography noselect mceNonEditable" data-reflist="[&quot;1352741480&quot;,&quot;1009922757&quot;,&quot;1027811230&quot;,&quot;795711616&quot;]">
<div id="abt-bibliography__container" class="abt-bibliography__container">
<div id="1352741480">
<div class="csl-entry flush">
<div class="csl-left-margin">1.</div>
<div class="csl-right-inline">Lindner F, Bentzen MM, Nebel B. The HERA approach to morally competent robots. In: <i>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</i>. IEEE; 2017. doi:<a href="https://doi.org/10.1109/iros.2017.8206625" target="_blank" rel="noopener noreferrer">10.1109/iros.2017.8206625</a></div>
</div>
</div>
<div id="1009922757">
<div class="csl-entry flush">
<div class="csl-left-margin">2.</div>
<div class="csl-right-inline">Vanderelst D, Winfield A. An architecture for ethical robots inspired by the simulation theory of cognition. <i>C</i>. 2018;48:56-66. doi:<a href="https://doi.org/10.1016/j.cogsys.2017.04.002" target="_blank" rel="noopener noreferrer">10.1016/j.cogsys.2017.04.002</a></div>
</div>
</div>
<div id="1027811230">
<div class="csl-entry flush">
<div class="csl-left-margin">3.</div>
<div class="csl-right-inline">Hesslow G. The current status of the simulation theory of cognition. <i>B</i>. 2012;1428:71-79. doi:<a href="https://doi.org/10.1016/j.brainres.2011.06.026" target="_blank" rel="noopener noreferrer">10.1016/j.brainres.2011.06.026</a></div>
</div>
</div>
<div id="795711616">
<div class="csl-entry flush">
<div class="csl-left-margin">4.</div>
<div class="csl-right-inline">Kortenkamp D, Simmons R, Brugali D. Robotic Systems Architectures and Programming. In: <i>Springer Handbook of Robotics</i>. Springer International Publishing; 2016:283-306. doi:<a href="https://doi.org/10.1007/978-3-319-32552-1_12" target="_blank" rel="noopener noreferrer">10.1007/978-3-319-32552-1_12</a></div>
</div>
</div>
</div>
</div>
]]></content:encoded>
					
					<wfw:commentRss>https://viveknallur.github.io/implementing-ethics-in-machines/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
